.. _migrate-schema-partner-collection:
.. _partner_collections:

========================================
Make Breaking Changes to Your Data Model  
========================================

.. meta::
   :description: Manually updating your Device Sync data model with breaking or non-breaking changes may require additional handling.

.. facet::
  :name: genre
  :values: tutorial

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

This page describes how to make breaking changes to your Device Sync data model. 

.. tip:: Make Breaking Changes with Development Mode  
   
   When possible, we recommend that apps in development use Development Mode to update their data model. When enabled, you can make breaking changes from yoru client code, and App Services automatically handles the updates to the server-side App Services schema. For more information, refer to :ref:`update-data-model-development-mode`.

.. - Automatic Server-Side Updates with Schema Versioning: Apps created after
..    [DATE TBD], 2024 can make breaking changes to the server-side App Services
..    schema. Device Sync creates a new schema version and automatically handles the
..    updates to the client object models. For more information, refer to :ref:`update-data-model-production-apps`.

.. You can contact support to enable either of these features.

.. TODO: Update with the correct date once it is available. 
.. TODO: Update to note support for changes from the client code once SDKs roll out versioning.

Breaking Changes: Quick Reference
---------------------------------

The following diagram shows the types of changes you can make and the 
process to manually perform the change. Each of these changes is explained 
in more detail in the table and sections below.

.. TODO: update to be specific to breaking changes only

.. figure:: /images/schema_changes.png
   :alt: Flow chart of schema changes
   :lightbox:

This table summarizes each type of change, and whether it is considered a breaking or 
non-breaking change when made to the server-side App Services schema or the client-side
SDK object model. 

.. list-table::
   :header-rows: 1
   :stub-columns: 1

   * - Type of Change
     - Server-Side Schema
     - Client-Side Object Model
   * - :ref:`Add an object type <schema-update-add-object-type>`
     - Non-breaking
     - Non-breaking
   * - :ref:`Add a default value on a property <schema-update-add-a-default-value>`
     - Non-breaking
     - Non-breaking
   * - :ref:`Add a required property <schema-update-add-required-property>`
     - Non-breaking
     - Non-breaking
   * - :ref:`Add an optional property <schema-update-add-optional-property>`
     - Non-breaking
     - Non-breaking
   * - :ref:`Remove an object type <schema-update-remove-object-type>`
     - Breaking
     - Non-breaking
   * - :ref:`Remove an optional or required property <schema-update-remove-property>`
     - Breaking
     - Non-breaking
   * - :ref:`Rename an object type <schema-update-change-object-type-name>`
     - Breaking
     - Breaking
   * - :ref:`Rename a property <schema-update-change-property-name>`
     - Breaking
     - Breaking
   * - :ref:`Change property type but keep the name <schema-update-change-property-type-but-keep-name>`
     - Breaking
     - Breaking
   * - :ref:`Change property's status between optional and required <schema-update-change-property-status>`
     - Breaking
     - Breaking

.. tip:: Remap a Name Instead of Renaming

   Because renaming a property or object type is a breaking change, several Device 
   SDKs support remapping a property or class name as a non-breaking workaround. For more
   details, refer to the
   :ref:`schema-update-change-property-name` section on this page.

Breaking and Non-Breaking Changes
---------------------------------

A **breaking change** is a change that requires additional action to handle
before it can be implemented. 

Breaking schema changes are tricky to manually implement and manage because clients that 
have not been updated to the updated schema still need to access
the data using old schema definitions, but updated clients need to 
work with the new schema changes as well.
As a result, breaking schema changes often mean that older clients can't 
to open a synced realm or they can give the appearance of data loss when server-side documents 
are unable to sync to client-side applications. Breaking changes can also 
prevent applications from automatically recovering from a 
:ref:`client reset <handle-a-client-reset>`.

When you make a breaking change to the server-side App Services schema, you
must either:  

- :ref:`Terminate <terminating-realm-sync>`, then :ref:`re-enable  <enable-sync>` Device Sync in the backend. 
- Create a partner collection with the desired changes, copy the old data to the
  collection, then set up triggers to ensure data consistency. This process is
  described in the :ref:`schema-partner_collection-strategy` section on this
  page.

.. include:: /includes/warn-terminate-sync-client-reset.rst

.. note:: Breaking Schema Changes Unsupported in CLI or Automated Deploy

   Because breaking schema changes require special handling, 
   App Services does not support making these changes using the {+cli+} CLI or 
   automated deploy with GitHub. You can make breaking changes through 
   the App Services UI.

A **non-breaking change** is a change that you can make in your server-side
schema or your client-side SDK object model without requiring additional handling in your
app. Also known as additive changes, they apply automatically to synced realms.

.. note:: Applying Non-Breaking Changes in Client May Require Migration

   You can make non-breaking changes to your server-side schema, then
   apply those changes to your client object model. However, if the
   client device has an existing realm file, you must
   perform a migration to apply those changes. For details, refer to the documentatino in your preferred SDK:

   - C++ SDK - migrations are currently unsupported 
   - :ref:`Flutter SDK - Update an Object Schema <flutter-update-realm-object-schema>`
   - :ref:`Java SDK - Modify an Object Schema <java-modify-an-object-schema>`
   - :ref:`Kotlin SDK - Update an Object Model <kotlin-change-object-model>`
   - :ref:`.NET SDK - Update an Object Model <dotnet-schema-versions-and-migrations>`
   - :ref:`Node.js SDK - Update an Object Model <node-modify-an-object-schema>`
   - :ref:`React Native SDK - Update an Object Model <react-native-schema-versions-and-migrations>`
   - :ref:`Swift SDK - Update an Object Model <ios-modify-an-object-schema>`

.. _schema-partner_collection-strategy:

Partner Collections Strategy
----------------------------

When you need to make a breaking schema change, you can use the partner
collection strategy to ensure that data flows in both directions.

A **partner collection** is a collection that contains the same data as
the original collection, but has the new schema definition in place. Partner
collections use database triggers to ensure that data flows in both directions,
meaning that when one collection is written to, the other is also written to 
(with the data modifications required for the new schema).

Example
~~~~~~~

The following demonstrates how to implement a breaking schema change using the
partner collection strategy for an updated ``Task`` collection schema. 

The JSON schema below is the initial collection. Note the ``_id`` field of type ``objectId``:

.. code-block:: json
    :caption: Initial Task Schema
    :emphasize-lines: 9-10

    {
        "title": "Task",
        "bsonType": "object",
        "required": [
            "_id",
            "name"
        ],
        "properties": {
            "_id": {
                "bsonType": "objectId"
            },
            "_partition": {
                "bsonType": "string"
            },
            "name": {
                "bsonType": "string"
            }
        }
    }

The *new* schema is the same, except we want the ``_id`` field to be a string:

.. code-block:: json
    :caption: New Task Schema 
    :emphasize-lines: 9-10

    {
        "title": "Task",
        "bsonType": "object",
        "required": [
            "_id",
            "name"
        ],
        "properties": {
            "_id": {
                "bsonType": "string"
            },
            "_partition": {
                "bsonType": "string"
            },
            "name": {
                "bsonType": "string"
            }
        }
    }

.. procedure::

   .. step:: Initialize Partner Collection with an Aggregation Pipeline

      Since breaking changes cannot be performed directly on a synced object
      schema, you must create a partner collection with a schema containing the
      required changes. You must ensure that the partner collection has the same
      data as the original collection so that newer clients can synchronize with
      older clients.

      The recommended approach to copying the data from your original collection to
      the new partner collection is to use the :manual:`Aggregation Framework
      </aggregation/>`.

      You can create and run an aggregation pipeline from the 
      `mongo shell <https://www.mongodb.com/docs/mongodb-shell/>`__,
      by using the :compass:`</aggregation-pipeline-builder/>`, or with the
      :atlas:`</data-explorer/cloud-agg-pipeline/>`.

      The pipeline will have the following stages:

      1. Match all the documents in the initial collection by passing
         an empty filter to the :manual:`$match operator
         </reference/operator/aggregation/match/>`.

      2. Modify the fields of the initial collection by using an
         :manual:`aggregation pipeline operator </reference/operator/aggregation/>`. In
         the following example, the data is transformed using the :manual:`$addFields
         operator </reference/operator/aggregation/addFields/>`. The ``_id`` field is
         transformed to a ``string`` type with the :manual:`$toString operator
         </reference/operator/aggregation/toString/>`.

      3. Write the transformed data to the partner collection by using the
         :manual:`$out operator </reference/operator/aggregation/out/>` and specifying
         the partner collection name. In this example, we wrote the data to a new
         collection named ``TaskV2``.

      Here the same pipeline as represented in the Atlas and Compass UIs. Note that
      both of these tools provide a preview of the changes; in this case, the
      conversion the ``_id`` field from an ObjectId to a string:

      .. figure:: /images/agg-in-atlas.png
         :alt: Atlas UI for Aggregation Builder

      The following example shows the complete aggregation pipeline as it would
      look if you used :mongosh:`mongosh </>` to do the conversion:

      .. code-block:: shell
         :caption: Match All Documents in the Initial Collection and Output Them to the Partner Collection

         use "<database-name>" // switch the current db to the db that the Task collection is stored in
         collection = db.Task;
         collection.aggregate([
           { $match: {} }, // match all documents in the Task collection
           {
             $addFields: { // transform the data
               _id: { $toString: "$_id" }, // change the _id field of the data to a string type
             },
           },
           { $out: "TaskV2" }, // output the data to a partner collection, TaskV2
         ]);

   .. step:: Set up Database Triggers for Partner Collection

      Once your partner collection is set up, you can use it to read existing data.
      However, any new writes to the data of *either collection* will not be
      in the other collection. This causes the old clients to be out of sync with the
      new clients.

      To ensure that data is reflected in both collections, you set up a
      :ref:`database trigger <create-a-database-trigger>` on each collection. When
      data is written to one collection, the trigger's function performs the write
      to the partner collection.

      Follow the steps in the :ref:`database trigger <create-a-database-trigger>`
      documentation to create a trigger that copies data from the ``Task`` collection to
      the ``TaskV2`` collection for all operation types. Repeat these steps to create
      a second trigger that copies data from the ``TaskV2`` collection to the
      ``Task`` collection. 

   .. step:: Add Trigger Functions

      Triggers require backing functions that run when the trigger fires. In this
      case, we need to create two functions: a forward-migration function and a
      reverse-migration function.

      The forward migration trigger listens for inserts, updates, and deletes in the
      Task collection, modifies them to reflect the TaskV2 collection's schema, and
      then applies them to the TaskV2 collection.

      To listen for changes to the TaskV2 collection and apply them to the Task
      collection, write a reverse-migration function for the TaskV2 collection's
      trigger. The reverse migration follows the same idea as the previous step.

      In the forward-migration function, we check which operation has triggered the
      function: if the operation type is ``Delete`` (meaning a document
      has been deleted in the Task collection), the document is also deleted in the
      TaskV2 collection. If the operation type is a ``Write`` (inserted or modified)
      event, an aggregation pipeline is created. In the pipeline, the inserted or
      modified document in the Task collection is extracted using the
      :manual:`$match operator </reference/operator/aggregation/match/>`. The
      extracted document is then transformed to adhere to the
      ``TaskV2`` collection's schema. Finally, the transformed data is written to the
      ``TaskV2`` collection by using the
      :manual:`$merge operator </reference/operator/aggregation/merge/>`:

      .. literalinclude:: /examples/generated/functions/copyTaskObjectToTaskV2.codeblock.copyTaskObject.js
         :language: javascript
         :caption: copyTaskObjectToTaskV2 function

      The reverse-migration function goes through similar steps as the example in the
      prior step. If a document has been deleted in one collection, the document is
      also deleted in the other collection. If the operation type is a write event,
      the changed document from ``TaskV2`` is extracted, transformed to match the
      Task collection's schema, and written into the ``Task`` collection:

      .. literalinclude:: /examples/generated/functions/copyTaskV2ObjectToTask.codeblock.copyTaskV2Object.js
         :language: javascript
         :caption: copyTaskV2ObjectToTask function
